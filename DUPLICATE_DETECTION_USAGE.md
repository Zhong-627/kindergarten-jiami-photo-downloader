# 重複檔案檢測功能使用指南

## 概述

加米幼兒園照片下載器現在支援智慧重複檔案檢測功能，可以：
- 自動識別相同內容的照片（即使檔名不同）
- 避免重複下載相同的照片
- 節省硬碟空間和下載時間
- 提供重複檔案清理工具

## 系統狀態

✅ **目前狀態**: 已完成優化，可以使用

📊 **發現的重複情況**:
- 總檔案數: 5,718
- 唯一照片數: 2,867  
- 重複檔案數: 2,851
- 可節省空間: 794MB

## 新增功能

### 1. 自動重複檢測
下載過程中會自動：
- 檢查 URL 雜湊值（快速檢測）
- 檢查檔案內容雜湊值（完整檢測）
- 跳過重複內容並顯示訊息

### 2. 增強的統計資訊
下載完成後會顯示：
- 唯一檔案數量
- 重複檔案統計
- 重複檔案範例

### 3. 重複檔案管理工具
提供專用工具處理已存在的重複檔案

## 使用方法

### 正常下載（會自動跳過重複）
```bash
# 下載最近一週的照片（自動跳過重複）
python3 main.py

# 測試模式，查看會下載什麼（不實際下載）
python3 main.py --dry-run

# 指定日期範圍
python3 main.py --start-date 2024-01-01 --end-date 2024-01-31
```

### 重複檔案管理

#### 查看重複檔案清單
```bash
python3 cleanup_duplicates.py --list
```

#### 預覽清理操作（不實際刪除）
```bash
python3 cleanup_duplicates.py --dry-run
```

#### 實際清理重複檔案
```bash
python3 cleanup_duplicates.py --clean
```

**注意**: 清理前會自動建立備份到 `/tmp/duplicate_cleanup_backup_*`

### 重建雜湊值索引（維護工具）
```bash
# 如果需要重建雜湊值索引（通常不需要）
python3 rebuild_hash_index.py
```

### 測試重複檢測功能
```bash
# 驗證重複檢測功能是否正常
python3 test_duplicate_detection.py
```

## 工作原理

### 檢測機制
1. **URL 雜湊值檢測**: 從照片 URL 提取雜湊值進行快速比對
2. **檔案內容檢測**: 下載後計算 MD5 雜湊值進行完整檢測
3. **雜湊值索引**: 建立雜湊值到檔案的映射，提升檢測效能

### 重複判定邏輯
- 相同雜湊值 = 相同內容 = 重複檔案
- 即使檔名、資料夾、上傳時間不同，內容相同就視為重複

### 處理策略
- **下載前**: 檢查 URL 雜湊值，如果已存在就跳過
- **下載後**: 檢查檔案雜湊值，如果重複就刪除新下載的檔案
- **清理時**: 保留每組重複檔案中的第一個，刪除其他的

## 檔案結構變化

### 下載歷史檔案結構
`download_history.json` 現在包含：
```json
{
  "downloads": {
    "檔名|URL": {
      "url": "原始URL",
      "filename": "本地檔名",
      "filepath": "完整路徑", 
      "file_size": 檔案大小,
      "download_time": "下載時間",
      "file_hash": "MD5雜湊值"
    }
  },
  "hash_index": {
    "雜湊值": [
      {
        "file_key": "檔名|URL",
        "filepath": "檔案路徑",
        "filename": "檔案名稱",
        "url": "原始URL"
      }
    ]
  }
}
```

## 常見問題

### Q: 為什麼會有這麼多重複檔案？
A: 因為：
- 同一張照片出現在不同相簿中
- 照片被重新上傳到不同日期的相簿
- 系統使用日期+流水號命名，無法識別相同內容

### Q: 清理重複檔案安全嗎？
A: 是的，因為：
- 清理前會建立完整備份
- 只刪除內容完全相同的檔案
- 每組重複檔案至少保留一份

### Q: 如何恢復誤刪的檔案？
A: 從備份目錄恢復：
- 備份位置：`/tmp/duplicate_cleanup_backup_YYYYMMDD_HHMMSS/`
- 備份包含所有被刪除的檔案

### Q: 重複檢測會影響下載速度嗎？
A: 影響很小：
- URL 雜湊值檢測幾乎即時
- 檔案雜湊值計算在下載完成後進行
- 雜湊值索引提供快速查詢

## 注意事項

1. **首次使用**: 需要先執行 `rebuild_hash_index.py` 建立索引
2. **備份重要**: 清理前確認備份已建立
3. **測試建議**: 先用 `--dry-run` 測試再實際執行
4. **空間需求**: 清理時會暫時需要額外空間建立備份

## 效益總結

使用新的重複檢測功能可以：
- **節省空間**: 可清理 794MB 重複檔案
- **提升效率**: 避免重複下載 2,851 個檔案  
- **智慧管理**: 自動識別重複內容，無需人工判斷
- **安全操作**: 完整備份機制，確保資料安全